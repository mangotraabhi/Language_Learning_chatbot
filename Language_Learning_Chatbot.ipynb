{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Setting Up the Environment**"
      ],
      "metadata": {
        "id": "9q9hVCBiuSgv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb1RQInitacm",
        "outputId": "f5c41345-50c9-420f-f19e-c05484ba0b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.66.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.9-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.3.9 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Key dependencies\n",
        "import openai\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import sqlite3\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "dtjZpNDztriX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Database Design**"
      ],
      "metadata": {
        "id": "-gYtHLgLul32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_database():\n",
        "    conn = sqlite3.connect('language_learning.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # User profiles table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS users (\n",
        "        user_id INTEGER PRIMARY KEY,\n",
        "        native_language TEXT,\n",
        "        learning_language TEXT,\n",
        "        proficiency_level TEXT\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # Learning sessions table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS sessions (\n",
        "        session_id INTEGER PRIMARY KEY,\n",
        "        user_id INTEGER,\n",
        "        scenario TEXT,\n",
        "        start_time TIMESTAMP,\n",
        "        end_time TIMESTAMP,\n",
        "        FOREIGN KEY (user_id) REFERENCES users (user_id)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # Mistakes tracking table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS mistakes (\n",
        "        mistake_id INTEGER PRIMARY KEY,\n",
        "        session_id INTEGER,\n",
        "        original_text TEXT,\n",
        "        correction TEXT,\n",
        "        mistake_type TEXT,\n",
        "        explanation TEXT,\n",
        "        FOREIGN KEY (session_id) REFERENCES sessions (session_id)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    conn.commit()\n",
        "    return conn"
      ],
      "metadata": {
        "id": "kE0icnd9urHu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. LLM Configuration**"
      ],
      "metadata": {
        "id": "d7Jg3gZVu37n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_llm(api_key=None):\n",
        "    # IMPORTANT: Enter your OpenAI API key when calling this function\n",
        "    # For testing, you can uncomment and use the line below:\n",
        "    api_key = \"your-api-key-here\"  # Replace with your actual OpenAI API key\n",
        "\n",
        "    # REMEMBER: Remove any hardcoded API keys before submission!\n",
        "\n",
        "    if api_key is None:\n",
        "        # Attempt to get from environment if not provided\n",
        "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "        if not api_key:\n",
        "            raise ValueError(\"No API key provided. Either pass an API key parameter or set the OPENAI_API_KEY environment variable.\")\n",
        "\n",
        "    # Set the environment variable for consistency\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "    # Using LangChain for conversation management\n",
        "    from langchain_openai import OpenAI\n",
        "\n",
        "    llm = OpenAI(temperature=0.7, openai_api_key=api_key)\n",
        "    memory = ConversationBufferMemory()\n",
        "    conversation = ConversationChain(\n",
        "        llm=llm,\n",
        "        memory=memory,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return conversation"
      ],
      "metadata": {
        "id": "YEOzPNTFu64P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Core Chatbot Logic**"
      ],
      "metadata": {
        "id": "qOUX5a5QvG7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageLearningBot:\n",
        "    def __init__(self, api_key):\n",
        "        self.db_conn = setup_database()\n",
        "        self.conversation = initialize_llm(api_key)\n",
        "        self.user_info = None\n",
        "        self.current_session = None\n",
        "        self.mistakes = []\n",
        "        self.scenarios = [\n",
        "            \"At a restaurant\", \"Shopping\", \"Asking for directions\",\n",
        "            \"At the doctor\", \"Job interview\", \"Casual conversation\"\n",
        "        ]\n",
        "\n",
        "    def start_session(self):\n",
        "        # Get user information\n",
        "        native_language = input(\"What language do you speak fluently? \")\n",
        "        learning_language = input(\"What language would you like to practice? \")\n",
        "        proficiency_level = input(\"What's your level (beginner/intermediate/advanced)? \")\n",
        "\n",
        "        # Store user info\n",
        "        cursor = self.db_conn.cursor()\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO users (native_language, learning_language, proficiency_level) VALUES (?, ?, ?)\",\n",
        "            (native_language, learning_language, proficiency_level)\n",
        "        )\n",
        "        self.db_conn.commit()\n",
        "        self.user_info = {\n",
        "            \"user_id\": cursor.lastrowid,\n",
        "            \"native_language\": native_language,\n",
        "            \"learning_language\": learning_language,\n",
        "            \"proficiency_level\": proficiency_level\n",
        "        }\n",
        "\n",
        "        # Choose scenario\n",
        "        print(\"\\nChoose a scenario to practice:\")\n",
        "        for i, scenario in enumerate(self.scenarios):\n",
        "            print(f\"{i+1}. {scenario}\")\n",
        "        scenario_choice = int(input(\"Enter number: \")) - 1\n",
        "        selected_scenario = self.scenarios[scenario_choice]\n",
        "\n",
        "        # Create new session\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO sessions (user_id, scenario, start_time) VALUES (?, ?, datetime('now'))\",\n",
        "            (self.user_info[\"user_id\"], selected_scenario)\n",
        "        )\n",
        "        self.db_conn.commit()\n",
        "        self.current_session = {\n",
        "            \"session_id\": cursor.lastrowid,\n",
        "            \"scenario\": selected_scenario\n",
        "        }\n",
        "\n",
        "        # Initialize conversation with system prompt\n",
        "        system_prompt = self._generate_system_prompt()\n",
        "        initial_response = self.conversation.predict(input=system_prompt)\n",
        "        print(initial_response)\n",
        "\n",
        "    def _generate_system_prompt(self):\n",
        "        prompt = f\"\"\"\n",
        "        You are a language learning assistant helping someone practice {self.user_info['learning_language']}.\n",
        "        The user's native language is {self.user_info['native_language']} and they are at a {self.user_info['proficiency_level']} level.\n",
        "\n",
        "        The conversation scenario is: {self.current_session['scenario']}\n",
        "\n",
        "        Please follow these guidelines:\n",
        "        1. Begin the conversation in {self.user_info['learning_language']}, appropriate for their level\n",
        "        2. Primarily use {self.user_info['learning_language']}, but explain complex things in {self.user_info['native_language']} if needed\n",
        "        3. When the user makes a language mistake, gently correct them in a supportive way\n",
        "        4. Keep the conversation focused on the scenario\n",
        "        5. Use appropriate vocabulary for a {self.user_info['proficiency_level']} level learner\n",
        "\n",
        "        Start by setting the scene for {self.current_session['scenario']} and begin the conversation.\n",
        "        \"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def chat(self):\n",
        "        self.start_session()\n",
        "\n",
        "        while True:\n",
        "            user_input = input(\"\\nYou: \")\n",
        "\n",
        "            if user_input.lower() in [\"exit\", \"quit\", \"end\"]:\n",
        "                self._end_session()\n",
        "                break\n",
        "\n",
        "            # Process user input with mistake detection\n",
        "            response, mistakes = self._process_input(user_input)\n",
        "\n",
        "            # Store any detected mistakes\n",
        "            for mistake in mistakes:\n",
        "                self._store_mistake(mistake)\n",
        "\n",
        "            print(f\"\\nBot: {response}\")\n",
        "\n",
        "    def _process_input(self, user_input):\n",
        "        # This function would send the user input to the LLM with a special prompt\n",
        "        # to both generate a response and analyze for mistakes\n",
        "        prompt = f\"\"\"\n",
        "        The user said: \"{user_input}\"\n",
        "\n",
        "        First, analyze if there are any language mistakes in their response.\n",
        "        If there are mistakes, identify them in this format:\n",
        "        MISTAKE: [original text]\n",
        "        CORRECTION: [corrected text]\n",
        "        TYPE: [grammar/vocabulary/pronunciation/etc]\n",
        "        EXPLANATION: [brief explanation of the mistake]\n",
        "\n",
        "        Then, respond to the user naturally as part of the ongoing conversation in {self.user_info['learning_language']}.\n",
        "        If there were mistakes, subtly incorporate the corrections into your response without making it feel like a formal correction.\n",
        "\n",
        "        Format your complete response as:\n",
        "        ANALYSIS: [your mistake analysis, or \"No mistakes detected\"]\n",
        "        RESPONSE: [your natural conversation response]\n",
        "        \"\"\"\n",
        "\n",
        "        full_response = self.conversation.predict(input=prompt)\n",
        "\n",
        "        # Parse the response to separate mistake analysis from conversation response\n",
        "        parts = full_response.split(\"RESPONSE:\")\n",
        "\n",
        "        if len(parts) > 1:\n",
        "            analysis = parts[0].replace(\"ANALYSIS:\", \"\").strip()\n",
        "            response = parts[1].strip()\n",
        "\n",
        "            # Extract mistakes from analysis\n",
        "            mistakes = []\n",
        "            if \"No mistakes detected\" not in analysis:\n",
        "                # Parse the mistakes using a more robust approach\n",
        "                mistake_entries = analysis.split(\"MISTAKE:\")\n",
        "                for entry in mistake_entries[1:]:  # Skip the first empty element\n",
        "                    try:\n",
        "                        mistake_parts = entry.split(\"\\n\")\n",
        "                        original = mistake_parts[0].strip()\n",
        "                        correction = mistake_parts[1].replace(\"CORRECTION:\", \"\").strip()\n",
        "                        mistake_type = mistake_parts[2].replace(\"TYPE:\", \"\").strip()\n",
        "                        explanation = mistake_parts[3].replace(\"EXPLANATION:\", \"\").strip()\n",
        "\n",
        "                        mistakes.append({\n",
        "                            \"original\": original,\n",
        "                            \"correction\": correction,\n",
        "                            \"type\": mistake_type,\n",
        "                            \"explanation\": explanation\n",
        "                        })\n",
        "                    except IndexError:\n",
        "                        # Skip malformed mistake entries\n",
        "                        pass\n",
        "        else:\n",
        "            # Fallback if response isn't formatted as expected\n",
        "            response = full_response\n",
        "            mistakes = []\n",
        "\n",
        "        return response, mistakes\n",
        "\n",
        "    def _store_mistake(self, mistake):\n",
        "        self.mistakes.append(mistake)\n",
        "\n",
        "        cursor = self.db_conn.cursor()\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO mistakes (session_id, original_text, correction, mistake_type, explanation) VALUES (?, ?, ?, ?, ?)\",\n",
        "            (\n",
        "                self.current_session[\"session_id\"],\n",
        "                mistake[\"original\"],\n",
        "                mistake[\"correction\"],\n",
        "                mistake[\"type\"],\n",
        "                mistake[\"explanation\"]\n",
        "            )\n",
        "        )\n",
        "        self.db_conn.commit()\n",
        "\n",
        "    def _end_session(self):\n",
        "        # Update session end time\n",
        "        cursor = self.db_conn.cursor()\n",
        "        cursor.execute(\n",
        "            \"UPDATE sessions SET end_time = datetime('now') WHERE session_id = ?\",\n",
        "            (self.current_session[\"session_id\"],)\n",
        "        )\n",
        "        self.db_conn.commit()\n",
        "\n",
        "        # Generate summary and feedback\n",
        "        self._generate_learning_summary()\n",
        "\n",
        "    def _generate_learning_summary(self):\n",
        "        # Retrieve mistakes for this session\n",
        "        cursor = self.db_conn.cursor()\n",
        "        cursor.execute(\n",
        "            \"SELECT original_text, correction, mistake_type, explanation FROM mistakes WHERE session_id = ?\",\n",
        "            (self.current_session[\"session_id\"],)\n",
        "        )\n",
        "        mistakes = cursor.fetchall()\n",
        "\n",
        "        if not mistakes:\n",
        "            print(\"\\n=== Session Summary ===\")\n",
        "            print(\"Great job! You had no mistakes in this session.\")\n",
        "            print(\"Keep practicing to build your fluency!\")\n",
        "            return\n",
        "\n",
        "        # Group mistakes by type\n",
        "        mistake_types = {}\n",
        "        for mistake in mistakes:\n",
        "            original, correction, mistake_type, explanation = mistake\n",
        "            if mistake_type not in mistake_types:\n",
        "                mistake_types[mistake_type] = []\n",
        "            mistake_types[mistake_type].append({\n",
        "                \"original\": original,\n",
        "                \"correction\": correction,\n",
        "                \"explanation\": explanation\n",
        "            })\n",
        "\n",
        "        # Create summary prompt for LLM\n",
        "        summary_prompt = f\"\"\"\n",
        "        The user has completed a language learning session in {self.user_info['learning_language']} at a {self.user_info['proficiency_level']} level.\n",
        "\n",
        "        Here are the mistakes they made during the conversation:\n",
        "        {json.dumps(mistake_types, indent=2)}\n",
        "\n",
        "        Please provide:\n",
        "        1. A supportive summary of their performance\n",
        "        2. Analysis of patterns in their mistakes\n",
        "        3. Specific advice on what areas to focus on for improvement\n",
        "        4. 2-3 practice exercises they could do to address their main issues\n",
        "\n",
        "        Keep your response encouraging and constructive.\n",
        "        \"\"\"\n",
        "\n",
        "        summary = self.conversation.predict(input=summary_prompt)\n",
        "\n",
        "        print(\"\\n=== Session Summary ===\")\n",
        "        print(summary)"
      ],
      "metadata": {
        "id": "nD8dYtUhvJnN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Main Application**\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "5zjxYqj-vZsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # In production, use environment variables or a config file\n",
        "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "    bot = LanguageLearningBot(api_key)\n",
        "    print(\"Welcome to the Language Learning Assistant!\")\n",
        "    print(\"Type 'exit', 'quit', or 'end' to finish the session.\")\n",
        "\n",
        "    bot.chat()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7RMephnvcMX",
        "outputId": "f148b492-5438-4a7a-b4b5-e26c26a933f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-f27d670e8f2e>:21: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n",
            "<ipython-input-5-f27d670e8f2e>:22: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation = ConversationChain(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Language Learning Assistant!\n",
            "Type 'exit', 'quit', or 'end' to finish the session.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yqXXNFfdvfRm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}